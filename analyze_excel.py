#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù…Ù„Ù Excel Ø§Ù„Ø®Ø§Øµ Ø¨Ù†Ø¸Ø§Ù… CRM
"""

import pandas as pd
import openpyxl
from openpyxl import load_workbook
import json
from datetime import datetime

def analyze_excel_file(file_path):
    """ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù…Ù„Ù Excel"""
    
    print("=" * 80)
    print("ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù…Ù„Ù Excel - Ù†Ø¸Ø§Ù… CRM")
    print("=" * 80)
    print()
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
    wb = load_workbook(file_path, data_only=True)
    
    analysis = {
        'file_info': {},
        'sheets': {},
        'data_structure': {},
        'relationships': [],
        'business_logic': {},
        'statistics': {}
    }
    
    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ø§Ù…Ø© Ø¹Ù† Ø§Ù„Ù…Ù„Ù
    analysis['file_info'] = {
        'file_name': file_path,
        'total_sheets': len(wb.sheetnames),
        'sheet_names': wb.sheetnames,
        'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    
    print(f"ğŸ“ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù: {file_path}")
    print(f"ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚: {len(wb.sheetnames)}")
    print(f"ğŸ“‹ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚: {', '.join(wb.sheetnames)}")
    print()
    
    # ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ ÙˆØ±Ù‚Ø©
    for sheet_name in wb.sheetnames:
        print("=" * 80)
        print(f"ğŸ“„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ±Ù‚Ø©: {sheet_name}")
        print("=" * 80)
        
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pandas
        df = pd.read_excel(file_path, sheet_name=sheet_name)
        ws = wb[sheet_name]
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ©
        sheet_analysis = {
            'name': sheet_name,
            'dimensions': {
                'rows': len(df),
                'columns': len(df.columns),
                'total_cells': len(df) * len(df.columns)
            },
            'columns': [],
            'data_types': {},
            'sample_data': {},
            'statistics': {},
            'null_values': {},
            'unique_values': {}
        }
        
        print(f"\nğŸ“ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯:")
        print(f"   - Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ: {len(df)}")
        print(f"   - Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {len(df.columns)}")
        print(f"   - Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø®Ù„Ø§ÙŠØ§: {len(df) * len(df.columns)}")
        
        print(f"\nğŸ“‹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ({len(df.columns)}):")
        for idx, col in enumerate(df.columns, 1):
            col_data = df[col]
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙˆØ¯
            col_info = {
                'name': str(col),
                'index': idx,
                'data_type': str(col_data.dtype),
                'non_null_count': int(col_data.count()),
                'null_count': int(col_data.isna().sum()),
                'null_percentage': float(col_data.isna().sum() / len(df) * 100) if len(df) > 0 else 0,
                'unique_count': int(col_data.nunique()),
                'unique_percentage': float(col_data.nunique() / len(df) * 100) if len(df) > 0 else 0
            }
            
            # Ø¥Ø¶Ø§ÙØ© Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            sample_values = col_data.dropna().head(5).tolist()
            col_info['sample_values'] = [str(v) for v in sample_values]
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
            if pd.api.types.is_numeric_dtype(col_data):
                col_info['statistics'] = {
                    'min': float(col_data.min()) if not col_data.isna().all() else None,
                    'max': float(col_data.max()) if not col_data.isna().all() else None,
                    'mean': float(col_data.mean()) if not col_data.isna().all() else None,
                    'median': float(col_data.median()) if not col_data.isna().all() else None,
                    'std': float(col_data.std()) if not col_data.isna().all() else None
                }
            
            # Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø© Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø°Ø§Øª Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø­Ø¯ÙˆØ¯Ø©
            if col_info['unique_count'] <= 20 and col_info['unique_count'] > 0:
                unique_vals = col_data.dropna().unique().tolist()
                col_info['all_unique_values'] = [str(v) for v in unique_vals]
            
            sheet_analysis['columns'].append(col_info)
            
            # Ø·Ø¨Ø§Ø¹Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¹Ù…ÙˆØ¯
            print(f"\n   {idx}. {col}")
            print(f"      - Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {col_info['data_type']}")
            print(f"      - Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„ÙØ§Ø±ØºØ©: {col_info['non_null_count']}")
            print(f"      - Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ©: {col_info['null_count']} ({col_info['null_percentage']:.1f}%)")
            print(f"      - Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø©: {col_info['unique_count']} ({col_info['unique_percentage']:.1f}%)")
            
            if col_info['sample_values']:
                print(f"      - Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {', '.join(col_info['sample_values'][:3])}")
            
            if 'statistics' in col_info:
                stats = col_info['statistics']
                if stats['min'] is not None:
                    print(f"      - Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: Min={stats['min']:.2f}, Max={stats['max']:.2f}, Mean={stats['mean']:.2f}")
            
            if 'all_unique_values' in col_info:
                print(f"      - Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø©: {', '.join(col_info['all_unique_values'])}")
        
        # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        print(f"\nğŸ“Š Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø£ÙˆÙ„ 5 ØµÙÙˆÙ):")
        print(df.head().to_string())
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
        print(f"\nğŸ”— ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©:")
        for col in df.columns:
            col_str = str(col).lower()
            if 'id' in col_str:
                print(f"   - {col}: Ù…Ø­ØªÙ…Ù„ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…ÙØªØ§Ø­ Ø£Ø³Ø§Ø³ÙŠ Ø£Ùˆ Ø®Ø§Ø±Ø¬ÙŠ")
            elif 'name' in col_str or 'Ø§Ø³Ù…' in col_str:
                print(f"   - {col}: Ø­Ù‚Ù„ Ø§Ø³Ù…")
            elif 'date' in col_str or 'ØªØ§Ø±ÙŠØ®' in col_str:
                print(f"   - {col}: Ø­Ù‚Ù„ ØªØ§Ø±ÙŠØ®")
            elif 'email' in col_str or 'Ø¨Ø±ÙŠØ¯' in col_str:
                print(f"   - {col}: Ø­Ù‚Ù„ Ø¨Ø±ÙŠØ¯ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ")
            elif 'phone' in col_str or 'Ù‡Ø§ØªÙ' in col_str or 'Ø¬ÙˆØ§Ù„' in col_str:
                print(f"   - {col}: Ø­Ù‚Ù„ Ù‡Ø§ØªÙ")
            elif 'status' in col_str or 'Ø­Ø§Ù„Ø©' in col_str:
                print(f"   - {col}: Ø­Ù‚Ù„ Ø­Ø§Ù„Ø©")
            elif 'price' in col_str or 'amount' in col_str or 'Ø³Ø¹Ø±' in col_str or 'Ù…Ø¨Ù„Øº' in col_str:
                print(f"   - {col}: Ø­Ù‚Ù„ Ù…Ø§Ù„ÙŠ")
        
        analysis['sheets'][sheet_name] = sheet_analysis
        print()
    
    # Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ Ù…Ù„Ù JSON
    output_file = 'excel_analysis.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(analysis, f, ensure_ascii=False, indent=2)
    
    print("=" * 80)
    print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„ ÙÙŠ Ø§Ù„Ù…Ù„Ù: {output_file}")
    print("=" * 80)
    
    return analysis

if __name__ == "__main__":
    file_path = "CRM (1).xlsx"
    analysis = analyze_excel_file(file_path)

